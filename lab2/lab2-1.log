Ryan Lin005131227Lab 2==========1) I ran $ export LC_ALL='C' then checked that LC_CTYPE="C" using the locale command2) I first checked if /usr/share/dict/words was sorted by executing $ sort -c /usr/share/dict/words, which indicated that it was not. I then cd'd into my working directory, created a new file using $ touch word, then sorted /usr/share/dict/words, outputting the  result into the word I had just created.3) Download html of assignment page/ $ wget http://web.cs.ucla.edu/classes/fall19/cs35L/assign/assign2.html4) i. tr -c 'A-Za-z' '[\n*]' < assign.htmlOutputs all characters satisfying the regex 'A-Za-z'; lines that have othernon-letter characters are replaced with newlines.ii. tr -cs 'A-Za-z' '[\n*]' < assign2.htmlThis command is identical to the last one except for the added -s option,which toggles the squeeze option. The squeeze option squeezes multiple occurrences of the characters listed in the last operand in the input into a single instance of the character. As a result, the output of this command gave us the output of the previous with one newline instead of multiple, making it easier to read.iii. tr -cs 'A-Za-z' '[\n*]' < assign2.html | sortThe output is now pipelined to the sort command, which sorts the output alphabetically. You can see repetitions of the same word in the output.iv.tr -cs 'A-Za-z' '[\n*]' < assign2.html | sort -uThe -u indicates the unique option, which checks for strict ordering and rids the output of duplicates. Multiple occurrences of the same word are reduced to one.v.tr -cs 'A-Za-z' '[\n*]' < assign2.html | sort -u | comm - wordsThe output of the last command is pipelined to comm, which prints out: Column 1: lines unique to the output of the command examined in 4.iv. compared           with the words fileColumn 2: lines unique to the words file compared with the output of 4.iv.Column 3: lines common to both the words file and the output of 4.iv.vi.tr -cs 'A-Za-z' '[\n*]' < assign2.html | sort -u | comm -23 - words # ENGLISHCHECKEROptions 2 and 3 suppress lines unique to the second argument and lines common to both arguments, respectively. The output is therefore the remaining column, lines unique to the first argument, namely the contents of column 3 from 4.v.5) Download Hawaiian page$ wget https://www.mauimapp.com/moolelo/hwnwdshw.htm6) buildwords script#!/usr/bin/bash#converts all uppercase characters to lowercasetr [:upper:] [:lower:] |#replaces all instances of the Hawaiian okina with an apostrophetr '`' "'" |#removes all instances of ?, <u>, and </u>sed 's/?\|<u>\|<\/u>//g' |#extracts all lines with a Hawaiian wordegrep "^([ ]*<td[^>]*>)[pkmnwlhaeiou' ]*(</td>[ ]*)$" |#removes all HTML tagssed -E 's/<[^>]*>//g' |#removes leading whitespacesed -E 's/^ *//g' |#separates words into different linessed -E 's/ /\n/g' |#sorts and deletes duplicatessort -u |#only keep nonempty linesgrep '.'7) Creating hwords:Make executable: $ chmod 755 buildwordsRun script:$ cat hwnwdshw.htm | ./buildwords > hwordsResult: 300 Hawaiian words found8) This revised english checker command replaces all Hawaiian okinas with an apostrophe, converts uppercase letters to lowercase, replaces all non-letters and non-apostrophe characters with a newline, sorts,and finally compares the output to the words file. Note: this command treats characters within html brackets as valid words to be checked.English checker:$ cat assign2.html | sed "s/\`/'/g" | tr '[:upper:]' '[:lower:]' | tr -cs "A-Za-z'" '[\n*]' | sort -u | grep '.' | comm -23 - words > misEnglishThe Hawaiian checker is identical to the English checker commandexcept the words file is replaced with the hwords file,which contains Hawaiian words instead of English ones.Hawaiian checker:$ cat assign2.html | sed "s/\`/'/g" | tr '[:upper:]' '[:lower:]' | tr -cs "A-Za-z'" '[\n*]' | sort -u | grep '.' | comm -23 - hwords > misHawaiian(used $ wc -l to grab number of rows in each file to determine number of words)Distinct misspelled words using ENGLISHCHECKER: 66 wordsDistinct misspelled words using HAWAIIANCHECKER: 557 wordsNumber of distinct words that ENGLISHCHECKER reports as misspelledbut HAWAIIANCHECKER does not: 3 wordsExamples: lau, wikiCommand used:$ cat misHawaiian | comm -13 - misEnglish > uniqueEnglishNumber of distinct words that HAWAIIANCHECKER reports as misspelled but ENGLISHCHECKER does not: 494 wordsExamples: about, currentCommand used: